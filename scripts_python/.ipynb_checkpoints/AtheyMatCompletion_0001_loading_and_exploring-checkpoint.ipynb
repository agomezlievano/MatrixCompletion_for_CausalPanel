{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "def ends(df, x=5):\n",
    "    return df.head(x).append(df.tail(x))\n",
    "setattr(pd.DataFrame,'ends',ends)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we're doing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many years now, I've been very interested in two related, but different questions:\n",
    "1. How to _apply_ Machine Learning to Economics by integrating ML into the usual econometric pipeline?\n",
    "2. What do the ML algorithms themselves teach us about how economies work.\n",
    "\n",
    "Recently, however, there seems to be a wave of interest (especially coming from the work coming from Stanford University) in these questions. This notebook is about the point 1. In particular, about the problem of estimating causal inference. (Unfortunately, point 2 seems to be still far from being considered.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to replicate the methodology (and hopefully results) of a recent paper in which the problem of causal inference is seen from the lens of the problem of ''matrix completion'' from the machine learning literature. I found out about this paper thanks to my dear friend Sid Ravinutala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I became aware of this paper, I've become increasingly interested in **Susan Athey**'s work, who's precisely preaching about the importance of using ML in economics. Let's see what she did here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper we want to reproduce is: \n",
    "\n",
    "''Matrix Completion Methods for Causal Panel Data Models''\n",
    "by Susan Athey, Mohsen Bayati, Nikolay Doudchenko, Guido Imbens, Khashayar Khosravi\n",
    "(NBER Working Paper No. 25132, also available in [arxiv](https://arxiv.org/pdf/1710.10251.pdf))\n",
    "\n",
    "NOTE: Check [her GitHub](https://github.com/susanathey/), as she made available her code in R. I'll try to implement her functions in Python instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup of the problem is to consider $N$ units across $T$ time steps. For each unit and time, there are two potential outcomes: $Y_{it}(0)$ if not treated, $Y_{it}(1)$ if treated. The treatment variable can be denoted by $W_{it}$. Hence, the realized outcome is $Y_{it}=Y_{it}(W_{it})$.\n",
    "\n",
    "The basic goal of causal identification is to estimate \n",
    "$$\\widehat{ATE} \\equiv \\frac{1}{NT}\\sum_{i,t}\\left(Y_{it}(1) - Y_{it}(0)\\right.)$$ \n",
    "The fundamental problem in causal identification, however, is that we never observe both $Y_{it}(0)$ and $Y_{it}(1)$. We either observe one, or the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athey's et al. (2018) solution is based on the following: First, $Y_{it}(0)$ (or $Y_{it}(1)$) is a $N\\times T$ matrix with missing values. Second, there are several methodologies to impute missing values in matrices. Hence, to get the ''counterfactual'' matrix, we can make use of the methods to impute missing values.\n",
    "\n",
    "Athey et al. focus specifically on imputing missing values in $Y_{it}(0)$ (i.e., the counterfactuals of those treated).\n",
    "\n",
    "Many algorithms for imputing missing values in matrices are based on matrix factorization methods. The different methods differ in the constraints. See [Udell et al. (2015)](https://arxiv.org/pdf/1410.0342.pdf) for a good review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athey's et al. (2018) use the method ''Nuclear Norm Matrix Completion Estimator''."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclear Norm Matrix Completion Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us represent the $N\\times T$ matrix we are interested in with $\\mathbf{Y}=\\mathbf{L^*}+\\boldsymbol{\\varepsilon}$, where $\\boldsymbol{\\varepsilon}$ can be considered as measurement error. Athey et al. set up the methodological problem as estimating\n",
    "$$\n",
    "\\widehat{\\mathbf{L}}=\\mathrm{arg min}_{\\mathbf{L}}\\left\\{\\frac{1}{\\left|\\mathcal{O}\\right|}\\left\\| \\mathbf{P}_{\\mathcal{O}}(\\mathbf{Y}-\\mathbf{L}) \\right\\|_{F}^2 + \\lambda \\left\\| \\mathbf{L} \\right\\|_{*} \\right\\}.\n",
    "$$\n",
    "\n",
    "- The set of _non-missing_ elements is defined by all $(i,t)\\in\\mathcal{O}$, while the set of _missing_ elements by  $(i,t)\\in\\mathcal{M}$.\n",
    "- The term $\\mathbf{P}_{\\mathcal{O}}(\\mathbf{A})$ is an operator that sets to $0$ all the elements in matrix $\\mathbf{A}$ which do not belong to the set of matrix elements $\\mathcal{O}$. In other words, we just keep the non-missing elements $\\mathcal{O}$, but we replace the missing elements with 0's. $\\mathbf{P}_{\\mathcal{O}}^{\\bot}(\\mathbf{A})$ would do the opposite.\n",
    "- The term $\\left\\| \\cdot \\right\\|_{F}^2$ is the Frobenius Norm: $\\left\\| \\mathbf{A} \\right\\|_{F}^2 = \\sum_{i,j}A_{i,j}^2=\\sum_k\\sigma_k(\\mathbf{A})^2$, where $\\sigma_i(\\mathbf{A})$ are the singular values of the matrix (given by a Singular Value Decomposition).\n",
    "- The term $\\left\\| \\cdot \\right\\|_{*}$ is the **Nuclear Norm** regularization of the minimization problem, given by $\\left\\| \\mathbf{A} \\right\\|_{*} = \\sum_k\\sigma_k(\\mathbf{A})$. Recall that the singular values are always non-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularization has a very important role in the problem, since we want $\\mathbf{L}$ to approximate the matrix $\\mathbf{Y}$, not make it equal, but only taking into account the information from the non-missing elements. The Nuclear Norm, from other matrix norms, is appropriate here because it makes the problem a convex optimization problem (see discussion in the paper, page. 14)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athey et al. propose an iterative algorithm which may seem weird at first as a solution to the problem. But before we go there, notice the following:\n",
    "- In principle, for a complete matrix $\\mathbf{Y}$, it holds that $\\mathbf{Y} = \\mathbf{P}_{\\mathcal{O}}(\\mathbf{Y}) + \\mathbf{P}_{\\mathcal{O}}^{\\bot}(\\mathbf{Y})$.\n",
    "- However, we do not have the values for the opperation $\\mathbf{P}_{\\mathcal{O}}^{\\bot}(\\mathbf{Y})$ to work. \n",
    "- Assuming that we had some $\\mathbf{L}_k$ that approximates the missing values of $\\mathbf{Y}$ we could have  $\\mathbf{P}_{\\mathcal{O}}^{\\bot}(\\mathbf{L}_k)$ in lieu.\n",
    "- But we want to use the information in $\\mathbf{P}_{\\mathcal{O}}(\\mathbf{Y})$ to generate the approximation $\\mathbf{L}_k$. The way to do this is by the approximation using the singular value decomposition. This is carried by the function $\\mathrm{shrink}_\\lambda(\\mathbf{A})$. \n",
    "- To be clear, $\\mathrm{shrink}_\\lambda(\\mathbf{A})$ is simply a function that returns an approximated version of the matrix $\\mathbf{A}$ using a singular value decomposition by taking only the singular values larger or equal than $\\lambda$. In other words, if $\\mathbf{A}=\\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^T$\n",
    "$$\n",
    "\\mathrm{shrink}_\\lambda(\\mathbf{A}) = \\mathbf{U}\\boldsymbol{\\Sigma}_{\\mathrm{reduced}}\\mathbf{V}^T,\n",
    "$$\n",
    "where $\\boldsymbol{\\Sigma}_{\\mathrm{reduced}}$ is equal to $\\boldsymbol{\\Sigma}$ except that all diagonal elements $k$ less than $\\sigma_k(\\mathbf{A})<\\lambda$ have been set to zero.\n",
    "- Now, if we initialize $\\mathbf{L}_1$ with some value, we can have an approximation for $\\mathbf{Y}$ because $\\mathbf{L}_2 = \\mathrm{shrink}_\\lambda(\\mathbf{P}_{\\mathcal{O}}(\\mathbf{Y}) + \\mathbf{P}_{\\mathcal{O}}^{\\bot}(\\mathbf{L}_1))$.\n",
    "- Maybe if we repeat this many times, it will converge to some reasonable solution such that $\\widehat{\\mathbf{L}}=\\lim_{n\\rightarrow\\infty}\\mathbf{L}_n$.\n",
    "\n",
    "I suppose they realized of this by thinking backwards. In other words, the solution $\\widehat{\\mathbf{L}}$ should satisfy the relation, for a given value of $\\lambda$: \n",
    "$$\\widehat{\\mathbf{L}} = \\mathrm{shrink}_\\lambda(\\mathbf{P}_{\\mathcal{O}}(\\mathbf{Y}) + \\mathbf{P}_{\\mathcal{O}}^{\\bot}(\\widehat{\\mathbf{L}})).$$ This is what's behind the iterative estimation algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"Matrix-Completion with Nuclear Norm Minimization\" estimator (MCNNM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, they write it like:\n",
    "$$\n",
    "\\mathbf{L}_{k+1}(\\lambda, \\mathcal{O})=\\mathrm{shrink}_{\\frac{\\lambda |\\mathcal{O}| }{2}}\\left\\{\\mathbf{P}_{\\mathcal{O}}(\\mathbf{Y}) + \\mathbf{P}_{\\mathcal{O}}^{\\bot}(\\mathbf{L}_{k}(\\lambda, \\mathcal{O}))\\right\\}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's begin with the P operators\n",
    "def PO_operator(Amat, setO):\n",
    "    \"\"\"\n",
    "    Set all elements that are not in setO to 0. It assumes that setO\n",
    "    comes from applying np.nonzero(A==condition) to a matrix.\n",
    "    \"\"\"\n",
    "    Anew = np.zeros_like(Amat)\n",
    "    Anew[setO] = Amat[setO]\n",
    "\n",
    "    return Anew\n",
    "\n",
    "def POcomp_operator(Amat, setO):\n",
    "    \"\"\"\n",
    "    The complement of PO_operator.\n",
    "    Set all elements that are in setO to 0. It assumes that setO\n",
    "    comes from applying np.nonzero(A==condition) to a matrix.\n",
    "    \"\"\"\n",
    "    Anew = np.copy(Amat)\n",
    "    Anew[setO] = 0\n",
    "\n",
    "    return Anew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets code the shrink operator\n",
    "def shrink(Amat, lamb=0, doprint=False):\n",
    "    \"\"\"\n",
    "    This generates a reduced version of A given by the singular value decomposition.\n",
    "    It only takes the singular above lamb.\n",
    "    \"\"\"\n",
    "    U, Sigma, VT = np.linalg.svd(Amat, full_matrices=False)\n",
    "    \n",
    "    if(doprint): print(Sigma)\n",
    "    \n",
    "    Sigma[Sigma < lamb] = 0\n",
    "    \n",
    "    return U@np.diag(Sigma)@VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function\n",
    "def mcnnm_loss(y_true, y_pred, setO, doprint=False):\n",
    "    Ocardinality = len(setO[0])\n",
    "    diffmat = y_true - y_pred\n",
    "    if(doprint): print(diffmat)\n",
    "    outmat = PO_operator(diffmat, setO)**2\n",
    "    return (outmat.sum().sum()/Ocardinality)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are to create artificial treatments\n",
    "def simul_adopt(Ymat, treated_units, t0):\n",
    "    \"\"\"\n",
    "    The function assumes that t0 are integer values that go\n",
    "    from 1 to T, where T is the wide length of the matrix Ymat.\n",
    "    \"\"\"\n",
    "    Ynew = Ymat.copy()\n",
    "    Ynew[treated_units, t0:] = np.nan\n",
    "    return Ynew\n",
    "\n",
    "def stag_adopt(Ymat, treated_units, t0):\n",
    "    \"\"\"\n",
    "    Here we assume that units get treated at times \n",
    "    t after t0, chosen uniformly at random from the \n",
    "    remaining times.\n",
    "    \"\"\"\n",
    "    N, T = Ymat.shape\n",
    "    ts = np.random.choice(np.arange(t0,T), size = len(treated_units))\n",
    "    Ynew = Ymat.copy()\n",
    "    for i, unit in enumerate(treated_units):\n",
    "        Ynew[unit,ts[i]:] = np.nan\n",
    "    return Ynew\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Matrix-Completion with Nuclear Norm Minimization\" estimator\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class MatrixCompletion_NNM(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This implements the iterative procedure to estimate L. \n",
    "    Since L is really the matrix Y, but with the missing values\n",
    "    imputed, we chose the Transformer 'Mixin'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    setOk : array-like\n",
    "        This comes, for example, from applying np.nonzero(A==condition) to a matrix\n",
    "    \n",
    "    missing_values : number, string, np.nan (default) or None\n",
    "        The placeholder for the missing values. All occurrences of\n",
    "        `missing_values` will be imputed.\n",
    "        \n",
    "    lamb : int (default=0)\n",
    "        This is the regularization parameter, which should be non-negative since\n",
    "        it is a minimization procedure.\n",
    "        \n",
    "    epsilon : float (default=0.001)\n",
    "        Desired accuracy of the estimation.\n",
    "    \n",
    "    max_iters : integer (default=100)\n",
    "    \n",
    "    doprint : boolean, optional (default=False)\n",
    "        Prints different results of the estimation steps.\n",
    "        \n",
    "    printbatch : integer, optional if doprint==True (default=10)\n",
    "        After how many iterations to print the loss function.\n",
    "        \n",
    "    copy : boolean, optional, default True\n",
    "        Set to False to perform inplace row normalization and avoid a\n",
    "        copy (if the input is already a numpy array).\n",
    "    \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    Lest_ : array-like, shape (N, T)\n",
    "        This is the estimate of L.\n",
    "    \n",
    "    loss_ : float\n",
    "        The root-square of the mean square error of the observed elements.\n",
    "        \n",
    "    iters_ : int\n",
    "        Number of iterations it took the algorithm to get the desired\n",
    "        precision given by the parameter 'epsilon'.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> data = np.array([[1,2,np.nan, 0],[np.nan,2,2,1],[3,0,1,3],[0,0,2,np.nan]])\n",
    "    >>> observedset = np.nonzero(~np.isnan(data))\n",
    "    >>> my_mcnnm = MatrixCompletion_NNM(setOk=observedset, lamb=2.5, epsilon=10**(-6), doprint=False)\n",
    "    >>> print(data)\n",
    "    [[  1.   2.  nan   0.]\n",
    "    [ nan   2.   2.   1.]\n",
    "    [  3.   0.   1.   3.]\n",
    "    [  0.   0.   2.  nan]]\n",
    "    >>> print(my_mcnnm.fit(data))\n",
    "    MatrixCompletion_NNM(copy=True, doprint=False, epsilon=1e-06, lamb=2.5,\n",
    "               max_iters=100, printbatch=10,\n",
    "               setOk=(array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3], dtype=int64), \n",
    "               array([0, 1, 3, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2], dtype=int64)))\n",
    "    >>> print(my_mcnnm.transform(data))\n",
    "    [[ 0.98082397  2.00915981  3.49022202  0.01813745]\n",
    "     [ 1.55601129  1.33063721  2.38547663  0.97025289]\n",
    "     [ 3.00567286  0.33134019  0.80761928  3.00948113]\n",
    "     [ 0.0419737   0.87320627  1.48553996 -0.39839039]]\n",
    "    >>> print(my_mcnnm.fit_transform(data))\n",
    "    [[ 0.98082397  2.00915981  3.49022202  0.01813745]\n",
    "     [ 1.55601129  1.33063721  2.38547663  0.97025289]\n",
    "     [ 3.00567286  0.33134019  0.80761928  3.00948113]\n",
    "     [ 0.0419737   0.87320627  1.48553996 -0.39839039]]\n",
    "    >>> print(my_mcnnm.transform([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]]))\n",
    "    [[ 0.98082397  2.00915981  3.49022202  0.01813745]\n",
    "     [ 1.55601129  1.33063721  2.38547663  0.97025289]\n",
    "     [ 3.00567286  0.33134019  0.80761928  3.00948113]\n",
    "     [ 0.0419737   0.87320627  1.48553996 -0.39839039]]\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, setOk=None, #missing_values=np.nan, \n",
    "                 lamb=0, epsilon=0.001, max_iters=100, \n",
    "                 doprint=False, printbatch=10, copy=True):\n",
    "        self.setOk = setOk \n",
    "        #self.missing_values = missing_values \n",
    "        self.lamb = lamb \n",
    "        self.epsilon = epsilon \n",
    "        self.max_iters = max_iters \n",
    "        self.doprint = doprint \n",
    "        self.printbatch = printbatch\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the estimator to the matrix X (which is \n",
    "        really the matrix Y in Athey et al.'s paper).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : Ignored\n",
    "            There is no need of a target in a transformer, yet the pipeline API\n",
    "            requires this parameter.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        # First, I should check that the missing values are right\n",
    "        #Ynew = np.zeros_like(self.Ymat)\n",
    "        #Ynew = self.missing_values\n",
    "        #Ynew[self.setOk] = self.Ymat[self.setOk]\n",
    "\n",
    "        assert (len(self.setOk) > 0), \"setOk should be a non-empty array\"\n",
    "        assert (self.lamb > 0), \"lamb is the lambda parameter which should be larger than zero\"\n",
    "\n",
    "        N, T = X.shape\n",
    "\n",
    "        # Initialize L to the observed (non-missing) values of Y given by the set setOk\n",
    "        Lprev = PO_operator(X, self.setOk)\n",
    "\n",
    "        # Initialization of error with a highvalue and the iteration\n",
    "        error = N*T*10**3\n",
    "        iteration = 0\n",
    "\n",
    "        while((error > self.epsilon) and (iteration < self.max_iters)):\n",
    "            Lnext = shrink(PO_operator(X, self.setOk) + \n",
    "                           POcomp_operator(Lprev, self.setOk), lamb = self.lamb)\n",
    "\n",
    "            # Updating values\n",
    "            Lprev = Lnext.copy()\n",
    "            error = mcnnm_loss(X, Lprev, self.setOk)\n",
    "            iteration = iteration + 1\n",
    "\n",
    "            if(self.doprint and (iteration%self.printbatch==0 or iteration==1)):\n",
    "                print(\"Iteration {}\\t Current loss: {}\".format(iteration, error))\n",
    "\n",
    "        if(self.doprint):\n",
    "            print(\"\")\n",
    "            print(\"Final values:\")\n",
    "            print(\"Iteration {}\\t Current loss: {}\".format(iteration, error))\n",
    "            print(\"\")\n",
    "            print(X)\n",
    "            print(np.round(Lnext, 2))\n",
    "        \n",
    "        self.iters_ = iteration\n",
    "        self.loss_ = error\n",
    "        self.Lest_ = Lnext\n",
    "        \n",
    "        # Return the transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" \n",
    "        Actually returning the estimated matrix, in which we have \n",
    "        imputed the missing values of X (matrix Y).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse-matrix}, shape (N, T)\n",
    "            The input data to complete.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed : array, shape (N, T)\n",
    "            The array the completed matrix.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            getattr(self, \"Lest_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must estimate the model before transforming the data!\")\n",
    "        \n",
    "        return self.Lest_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2. nan  0.]\n",
      " [nan  2.  2.  1.]\n",
      " [ 3.  0.  1.  3.]\n",
      " [ 0.  0.  2. nan]]\n",
      "MatrixCompletion_NNM(copy=True, doprint=False, epsilon=1e-06, lamb=2.5,\n",
      "           max_iters=100, printbatch=10,\n",
      "           setOk=(array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3], dtype=int64), array([0, 1, 3, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2], dtype=int64)))\n",
      "[[ 0.98082397  2.00915981  3.49022202  0.01813745]\n",
      " [ 1.55601129  1.33063721  2.38547663  0.97025289]\n",
      " [ 3.00567286  0.33134019  0.80761928  3.00948113]\n",
      " [ 0.0419737   0.87320627  1.48553996 -0.39839039]]\n",
      "[[ 0.98082397  2.00915981  3.49022202  0.01813745]\n",
      " [ 1.55601129  1.33063721  2.38547663  0.97025289]\n",
      " [ 3.00567286  0.33134019  0.80761928  3.00948113]\n",
      " [ 0.0419737   0.87320627  1.48553996 -0.39839039]]\n",
      "[[ 0.98082397  2.00915981  3.49022202  0.01813745]\n",
      " [ 1.55601129  1.33063721  2.38547663  0.97025289]\n",
      " [ 3.00567286  0.33134019  0.80761928  3.00948113]\n",
      " [ 0.0419737   0.87320627  1.48553996 -0.39839039]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,2,np.nan, 0],[np.nan,2,2,1],[3,0,1,3],[0,0,2,np.nan]])\n",
    "observedset = np.nonzero(~np.isnan(data))\n",
    "\n",
    "my_mcnnm = MatrixCompletion_NNM(setOk=observedset, lamb=2.5, epsilon=10**(-6), doprint=False)\n",
    "\n",
    "#print(my_mcnnm.transform(data))\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(my_mcnnm.fit(data))\n",
    "\n",
    "myLest = my_mcnnm.transform(data)\n",
    "print(myLest)\n",
    "\n",
    "print(my_mcnnm.fit_transform(data))\n",
    "\n",
    "print(my_mcnnm.transform([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complicated example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.10328107 10.6648671  10.57180318 12.44890752 11.39709621 10.73603842\n",
      "  13.21498354 16.19970787 10.61622969  9.66535008  8.55253032  9.1258884\n",
      "  14.40253861  9.01607998  6.94348485  5.51480246  7.28822193  5.23866253\n",
      "   6.90079247  3.88965889]\n",
      " [21.88890948 11.26072961 10.29541941 10.1286228  12.79766947 10.82702714\n",
      "  17.6122818  13.06012541 10.97316879  9.5206277   8.21511212  9.00004526\n",
      "   8.55465696 12.82918008  5.91122296  5.18522737  5.89082523  6.06316366\n",
      "   7.98973347  2.85037117]\n",
      " [17.77563759 10.34620198 11.35326824 12.25000737 13.44681873  9.0891511\n",
      "  11.15909003 22.55299747  8.10691117 10.79262544  9.02163773  8.12702123\n",
      "   8.22280831  6.35291672  5.84053829  7.72387347  7.85128493  6.46203566\n",
      "   9.22707783  7.7270509 ]\n",
      " [15.2147294  11.2093389  12.14782555 15.44723685  9.64785691 12.5062235\n",
      "   8.29841629  8.53004749  8.04697099 13.92129237 15.43161333  7.03545896\n",
      "   7.21498055  5.82608469 10.53379929  6.52167672  4.75697224  8.11821437\n",
      "  20.78094771  5.10830387]\n",
      " [ 9.52348628  8.95221538 12.07090728  9.91254253  9.84730408  8.10823486\n",
      "   9.36773651 11.08853351  6.84179353  7.53769926  8.46929352  7.9833121\n",
      "   5.81892279 12.47130193  5.97260156  8.41488008 11.45690951  3.90397935\n",
      "   4.93495634  1.96953443]\n",
      " [ 8.72694301  8.13180309 10.55138339 11.53632512 11.41207622 18.5416557\n",
      "   7.19080729  7.48316184  7.47332064  7.29498854  7.17944472  7.94544098\n",
      "   8.10235371  7.59952749 10.06405092  5.45220752  5.85434651  5.89488396\n",
      "   4.40670464  8.10229337]\n",
      " [ 7.81902977 10.81347918  9.48787907  8.95411302  6.71917279 13.35617221\n",
      "  13.50407265  6.06217271 10.03789576 10.3400107   6.84714801  7.06573067\n",
      "   8.07502493  4.36457402  5.02646321  4.67899621 10.98982934  3.793435\n",
      "   9.22523374  9.20743751]\n",
      " [11.6175803   6.2054033   5.96139417  5.88790924  5.84161805 12.07509932\n",
      "   8.17204359  6.8440686   8.81592306  7.08803441  7.22555726  8.88650669\n",
      "   6.13406239  6.15462111  4.15862062  6.37164158  3.56642471  5.4580761\n",
      "   5.15174575  2.29627007]\n",
      " [ 5.84221427  6.78405974 10.45956196  6.19514392 10.36033197  6.93605285\n",
      "   7.00998471  3.96814743  6.36566054  5.83187993  8.03692905 16.86103267\n",
      "   4.96764418  4.3024804   3.56170653  7.96363152  2.5075037   4.29159833\n",
      "   3.37802737  2.1321311 ]\n",
      " [ 5.50172249  4.01996341  3.74759091 10.51724941  7.06399573  5.49264959\n",
      "   4.40485005  4.49972509 19.40527797  3.41708564  5.87445596  6.03701614\n",
      "   6.23107646  5.39200769  5.8310882   2.649231    5.995086    5.56550596\n",
      "   3.22038087  7.31611845]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I set up a matrix full of values, with some order (in order to be predictable)\n",
    "N, T = (10, 20)\n",
    "Yreal = np.array([[np.random.exponential(scale = 3, size = 1)[0] + ((T-j)**0.5)*np.log(N-i+1) for j in np.arange(T)] for i in np.arange(N)])\n",
    "print(Yreal)\n",
    "plt.imshow(Yreal, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the units treated, and the earliest time of treatment\n",
    "tr_units = np.arange(int(N/3),N)\n",
    "t0 = int(T/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.10328107 10.6648671  10.57180318 12.44890752 11.39709621 10.73603842\n",
      "  13.21498354 16.19970787 10.61622969  9.66535008  8.55253032  9.1258884\n",
      "  14.40253861  9.01607998  6.94348485  5.51480246  7.28822193  5.23866253\n",
      "   6.90079247  3.88965889]\n",
      " [21.88890948 11.26072961 10.29541941 10.1286228  12.79766947 10.82702714\n",
      "  17.6122818  13.06012541 10.97316879  9.5206277   8.21511212  9.00004526\n",
      "   8.55465696 12.82918008  5.91122296  5.18522737  5.89082523  6.06316366\n",
      "   7.98973347  2.85037117]\n",
      " [17.77563759 10.34620198 11.35326824 12.25000737 13.44681873  9.0891511\n",
      "  11.15909003 22.55299747  8.10691117 10.79262544  9.02163773  8.12702123\n",
      "   8.22280831  6.35291672  5.84053829  7.72387347  7.85128493  6.46203566\n",
      "   9.22707783  7.7270509 ]\n",
      " [15.2147294  11.2093389  12.14782555 15.44723685  9.64785691 12.5062235\n",
      "   8.29841629  8.53004749  8.04697099 13.92129237 15.43161333  7.03545896\n",
      "   7.21498055  5.82608469 10.53379929  6.52167672  4.75697224  8.11821437\n",
      "  20.78094771         nan]\n",
      " [ 9.52348628  8.95221538 12.07090728  9.91254253  9.84730408  8.10823486\n",
      "   9.36773651 11.08853351  6.84179353  7.53769926  8.46929352  7.9833121\n",
      "   5.81892279 12.47130193  5.97260156  8.41488008 11.45690951  3.90397935\n",
      "          nan         nan]\n",
      " [ 8.72694301  8.13180309 10.55138339 11.53632512 11.41207622 18.5416557\n",
      "   7.19080729  7.48316184  7.47332064  7.29498854  7.17944472  7.94544098\n",
      "   8.10235371         nan         nan         nan         nan         nan\n",
      "          nan         nan]\n",
      " [ 7.81902977 10.81347918  9.48787907  8.95411302  6.71917279 13.35617221\n",
      "  13.50407265  6.06217271 10.03789576 10.3400107   6.84714801  7.06573067\n",
      "          nan         nan         nan         nan         nan         nan\n",
      "          nan         nan]\n",
      " [11.6175803   6.2054033   5.96139417  5.88790924  5.84161805 12.07509932\n",
      "   8.17204359  6.8440686   8.81592306  7.08803441  7.22555726  8.88650669\n",
      "   6.13406239  6.15462111  4.15862062  6.37164158  3.56642471         nan\n",
      "          nan         nan]\n",
      " [ 5.84221427  6.78405974 10.45956196  6.19514392 10.36033197  6.93605285\n",
      "   7.00998471  3.96814743  6.36566054  5.83187993  8.03692905 16.86103267\n",
      "   4.96764418  4.3024804   3.56170653  7.96363152  2.5075037   4.29159833\n",
      "   3.37802737         nan]\n",
      " [ 5.50172249  4.01996341  3.74759091 10.51724941  7.06399573  5.49264959\n",
      "   4.40485005  4.49972509 19.40527797  3.41708564  5.87445596  6.03701614\n",
      "          nan         nan         nan         nan         nan         nan\n",
      "          nan         nan]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADKCAYAAACFWKrDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAECZJREFUeJzt3X9sVfd5x/HPgw0xxgaTHyQUR06YSvNjUkbkINr8UFSqhGRNWKZmUKVb1k5CaMtGpk0bU6W22n/NtmpZUnViaUa3RU20QLeockPIkmpaokAMIQEKFMhY+VUgMeDAAIP97I97vFmXe+3jPPfc62/3fkmWr+/5fh8/ORx/cu6595xj7i4AQDomNboBAMD4ENwAkBiCGwASQ3ADQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxDQXUXTq1Kk+ffr0UI3oGZ21OCN08uTJ4RqDg4PhGtH/lilTpoR7aGlpCdc4depUuMbQ0FBofi3+PSZNiu/vtLe3h2v09/eH5l+4cCHcw8WLF8M1avF3NjAw0PAezp07F5o/NDSkoaEhyzO2kOCePn26li5dGqoR3aiif+CSdM0114RrfPTRR+Ea0Q2iq6sr3MO8efPCNdavXx+ucfr06dD8aNhJ0mWXXRausWjRonCNV199NTT/0KFD4R76+vrCNWbNmhWucfjw4Yb3sHv37tD88WybHCoBgMQQ3ACQGIIbABKTK7jNbLGZ7TazvWa2quimAADVjRncZtYk6duS7pN0k6QvmtlNRTcGAKgszx73Akl73f19dx+Q9LykJcW2BQCoJk9wz5F0YMTPB7PnAAANkCe4K30g/JIzQsxsuZn1mlnv2bNn450BACrKE9wHJV074udOSZd82t3dV7t7t7t3T506tVb9AQDK5AnutyV90syuN7MpkpZJeqnYtgAA1Yx5yru7XzSzxyStl9Qk6Vl331F4ZwCAinJdq8TdeyT1FNwLACAHzpwEgMQQ3ACQGIIbABJTyPW4Ozs79cQTT4RqrFoVuyRK9LrNknTgwIGxB41h7ty54RrRaw0vXLgw3MObb74ZrlGLi9VHr7Nei5sHNDfH/2x6euJvGS1YsCA0f9euXeEeanEjhRMnToRrtLa2huZHb/wixa+9P56bfLDHDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEgMwQ0AiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBITCE3Ujhz5ozefvvtcI2I9vb20HxJamtrC9doaWkJ1zh+/Hho/rp168I9PPnkk+EaixcvDteI3phiYGAg3EMtbtJhZuEaa9euDc1393APXV1d4RpNTU3hGn19faH5M2bMCPdw5513hub39vbmHsseNwAkhuAGgMQQ3ACQGIIbABIzZnCb2bVm9rqZ7TSzHWa2sh6NAQAqy/OpkouS/sjdt5hZu6TNZrbB3X9ScG8AgArG3ON29yPuviV7/JGknZLmFN0YAKCycR3jNrPrJM2XtLHCsuVm1mtmvSdPnqxNdwCAS+QObjNrk7RW0uPu3l++3N1Xu3u3u3d3dHTUskcAwAi5gtvMJqsU2s+5e/w0PADAx5bnUyUm6buSdrr7t4pvCQAwmjx73LdL+k1JnzWzrdnX/QX3BQCoYsyPA7r7f0iKXxEHAFATnDkJAIkhuAEgMYVcj/v8+fPav39/qMa0adMaOl+SbrzxxnCNnp6ecI2bb745NH/Tpk3hHh544IFwjVpc//mGG24Izb/jjjvCPTz11FPhGs3N8T+96LXFa7EuNm/eHK5x9OjRcI3o38jTTz8d7mHWrFmh+WaWe2Wyxw0AiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASIzV4uL25a644gq/9957QzXOnTsXmh+94L4kHTp0KFyjFuv32LFjofkdHR3hHqIXiZdqc0OHqVOnhua3tbWFezh//ny4Ri22rYcffjg0f+3ateEeurq6wjXmzZsXrrFmzZrQ/L6+vnAPUWa22d2784xljxsAEkNwA0BiCG4ASAzBDQCJyR3cZtZkZu+Y2Q+LbAgAMLrx7HGvlLSzqEYAAPnkCm4z65T0q5KeKbYdAMBY8u5x/7WkP5E0VGAvAIAcxgxuM/u8pGPuvnmMccvNrNfMeqMnzwAAqsuzx327pAfNbL+k5yV91sz+qXyQu6929253725paalxmwCAYWMGt7v/mbt3uvt1kpZJes3dv1R4ZwCAivgcNwAkpnk8g939x5J+XEgnAIBc2OMGgMQQ3ACQGIIbABJTyI0UOjo6/O677w7ViH4WvBYXeG9vbw/XGBqKn7P0yCOPhOavXLky3ENz87jeDinM4OBgaH4ttvfW1tZwjUmT4vtML7/8crgGJg5upAAAv8AIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJTyNXxh4aGdPr06VCNefPmheafPHkyNF+Sjh8/Hq5x4MCBcI3Zs2eH5j/00EPhHtasWROu0d2d6xrxo4re0GHbtm3hHs6cOROu8cYbb4Rr4P8v9rgBIDEENwAkhuAGgMQQ3ACQmFzBbWYdZvaime0ys51m9umiGwMAVJb3LfonJb3s7l8wsymSWgvsCQAwijGD28ymS7pL0m9LkrsPSBooti0AQDV5DpXMlXRc0t+b2Ttm9oyZTSsfZGbLzazXzHovXLhQ80YBACV5grtZ0q2SvuPu8yWdkbSqfJC7r3b3bnfvnjx5co3bBAAMyxPcByUddPeN2c8vqhTkAIAGGDO43f3nkg6Y2aeypxZJ+kmhXQEAqsr7qZLfl/Rc9omS9yV9ubiWAACjyRXc7r5VUvwKQQCAMM6cBIDEENwAkBiCGwASU8iNFFpbWzV//vxQjQ0bNoTmDw4OhuZLkrtPiBonTpwIzX/nnXfCPUybdsk5V+NWi5tbHDt2LDS/FucYXHXVVeEat9xyS7hG1JEjR8I15syZE66xb9++cI3+/v5wjZSwxw0AiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNwA0BiCrke96lTp9TT0xOq0dbWFppfi+sdb9q0KVzjtttuC9d4/fXXwzWi9uzZE65x/vz5cI2BgYHQ/M7OznAPy5cvD9dYsWJFuMbZs2dD88+dOxfuoRbXJt+6dWu4xtVXXx2af+bMmXAPp0+fDtfIiz1uAEgMwQ0AiSG4ASAxBDcAJCZXcJvZH5rZDjPbbmbfN7OWohsDAFQ2ZnCb2RxJfyCp291/WVKTpGVFNwYAqCzvoZJmSVPNrFlSq6TDxbUEABjNmMHt7ock/aWkn0k6IumUu79SdGMAgMryHCqZKWmJpOslfULSNDP7UoVxy82s18x6BwcHa98pAEBSvkMln5P0n+5+3N0vSFon6TPlg9x9tbt3u3t3U1NTrfsEAGTyBPfPJC00s1YzM0mLJO0sti0AQDV5jnFvlPSipC2StmVzVhfcFwCgilwXmXL3r0v6esG9AABy4MxJAEgMwQ0AiSG4ASAx5u41L9rS0uJdXV2hGh9++GFo/sWLF0PzJWnp0qXhGtu3bw/X+OCDD0Lz+/v7wz2UPlAU89prr4VrdHd3h+ZHt0tJmjQpvr+zbdu2cA38YjGzze6eawNnjxsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEgMwQ0AiSG4ASAxBDcAJIbgBoDEENwAkJhCbqRgZscl/dcoQ66UFLs7QH3QZ+2k0KNEn7VGn/l1uftVeQYWEtxj/lKz3rx3emgk+qydFHqU6LPW6LMYHCoBgMQQ3ACQmEYF9+oG/d7xos/aSaFHiT5rjT4L0JBj3ACAj49DJQCQmEKD28wWm9luM9trZqsqLL/MzF7Ilm80s+uK7KdKj9ea2etmttPMdpjZygpj7jazU2a2Nfv6Wr37zPrYb2bbsh56Kyw3M/ubbH2+Z2a31rm/T41YR1vNrN/MHi8b05B1aWbPmtkxM9s+4rnLzWyDme3Jvs+sMvfRbMweM3u0AX3+hZntyv5Nf2BmHVXmjrp91KHPb5jZoRH/tvdXmTtqLtShzxdG9LjfzLZWmVu39Tlu7l7Il6QmSfskzZU0RdK7km4qG/O7kv42e7xM0gtF9TNKn7Ml3Zo9bpf00wp93i3ph/XurUKv+yVdOcry+yX9SJJJWihpYwN7bZL0c5U+m9rwdSnpLkm3Sto+4rknJK3KHq+S9M0K8y6X9H72fWb2eGad+7xHUnP2+JuV+syzfdShz29I+uMc28WouVB0n2XL/0rS1xq9Psf7VeQe9wJJe939fXcfkPS8pCVlY5ZI+l72+EVJi8zMCuzpEu5+xN23ZI8/krRT0px69lBDSyT9g5e8JanDzGY3qJdFkva5+2gnYtWNu/+7pL6yp0duf9+T9GsVpt4raYO797n7CUkbJC2uZ5/u/oq7X8x+fEtSZ1G/P68q6zOPPLlQM6P1mWXNb0j6flG/vyhFBvccSQdG/HxQlwbi/47JNsxTkq4osKdRZYdq5kvaWGHxp83sXTP7kZndXNfG/o9LesXMNpvZ8grL86zzelmm6n8QE2FdStLV7n5EKv0PXNKsCmMm0jqVpK+o9KqqkrG2j3p4LDuk82yVQ08TaX3eKemou++psnwirM+KigzuSnvO5R9hyTOmLsysTdJaSY+7e3/Z4i0qveS/RdJTkv6l3v1lbnf3WyXdJ+n3zOyusuUTYn2a2RRJD0r65wqLJ8q6zGtCrFNJMrOvSroo6bkqQ8baPor2HUm/JOlXJB1R6TBEuQmzPiV9UaPvbTd6fVZVZHAflHTtiJ87JR2uNsbMmiXN0Md7+RViZpNVCu3n3H1d+XJ373f309njHkmTzezKOrcpdz+cfT8m6QcqvewcKc86r4f7JG1x96PlCybKuswcHT6UlH0/VmHMhFin2Zuin5f0iGcHYMvl2D4K5e5H3X3Q3Yck/V2V3z9R1mezpF+X9EK1MY1en6MpMrjflvRJM7s+2wNbJumlsjEvSRp+l/4Lkl6rtlEWJTvO9V1JO939W1XGXDN87N3MFqi03j6sX5eSmU0zs/bhxyq9YbW9bNhLkn4r+3TJQkmnhg8F1FnVPZmJsC5HGLn9PSrpXyuMWS/pHjObmb30vyd7rm7MbLGkP5X0oLv/d5UxebaPQpW9n/JQld+fJxfq4XOSdrn7wUoLJ8L6HFWR73yq9CmHn6r0LvJXs+f+XKUNUJJaVHo5vVfSJklz6/3urKQ7VHqp9p6krdnX/ZJWSFqRjXlM0g6V3gF/S9JnGtDn3Oz3v5v1Mrw+R/Zpkr6dre9tkrob0GerSkE8Y8RzDV+XKv2P5IikCyrt9f2OSu+n/JukPdn3y7Ox3ZKeGTH3K9k2ulfSlxvQ516VjgsPb5/Dn8T6hKSe0baPOvf5j9l2955KYTy7vM/s50tyoZ59Zs+vGd4mR4xt2Poc7xdnTgJAYjhzEgASQ3ADQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJCY/wHyhgxOTMnYPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Yobs = stag_adopt(Yreal, tr_units, t0)\n",
    "\n",
    "print(Yobs)\n",
    "plt.imshow(Yobs, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\t Current loss: 1.556848317504585\n",
      "Iteration 20\t Current loss: 0.006358421149145352\n",
      "Iteration 40\t Current loss: 1.0369413036351632e-05\n",
      "\n",
      "Final values:\n",
      "Iteration 48\t Current loss: 7.934622625365779e-07\n",
      "\n",
      "[[11.10328107 10.6648671  10.57180318 12.44890752 11.39709621 10.73603842\n",
      "  13.21498354 16.19970787 10.61622969  9.66535008  8.55253032  9.1258884\n",
      "  14.40253861  9.01607998  6.94348485  5.51480246  7.28822193  5.23866253\n",
      "   6.90079247  3.88965889]\n",
      " [21.88890948 11.26072961 10.29541941 10.1286228  12.79766947 10.82702714\n",
      "  17.6122818  13.06012541 10.97316879  9.5206277   8.21511212  9.00004526\n",
      "   8.55465696 12.82918008  5.91122296  5.18522737  5.89082523  6.06316366\n",
      "   7.98973347  2.85037117]\n",
      " [17.77563759 10.34620198 11.35326824 12.25000737 13.44681873  9.0891511\n",
      "  11.15909003 22.55299747  8.10691117 10.79262544  9.02163773  8.12702123\n",
      "   8.22280831  6.35291672  5.84053829  7.72387347  7.85128493  6.46203566\n",
      "   9.22707783  7.7270509 ]\n",
      " [15.2147294  11.2093389  12.14782555 15.44723685  9.64785691 12.5062235\n",
      "   8.29841629  8.53004749  8.04697099 13.92129237 15.43161333  7.03545896\n",
      "   7.21498055  5.82608469 10.53379929  6.52167672  4.75697224  8.11821437\n",
      "  20.78094771         nan]\n",
      " [ 9.52348628  8.95221538 12.07090728  9.91254253  9.84730408  8.10823486\n",
      "   9.36773651 11.08853351  6.84179353  7.53769926  8.46929352  7.9833121\n",
      "   5.81892279 12.47130193  5.97260156  8.41488008 11.45690951  3.90397935\n",
      "          nan         nan]\n",
      " [ 8.72694301  8.13180309 10.55138339 11.53632512 11.41207622 18.5416557\n",
      "   7.19080729  7.48316184  7.47332064  7.29498854  7.17944472  7.94544098\n",
      "   8.10235371         nan         nan         nan         nan         nan\n",
      "          nan         nan]\n",
      " [ 7.81902977 10.81347918  9.48787907  8.95411302  6.71917279 13.35617221\n",
      "  13.50407265  6.06217271 10.03789576 10.3400107   6.84714801  7.06573067\n",
      "          nan         nan         nan         nan         nan         nan\n",
      "          nan         nan]\n",
      " [11.6175803   6.2054033   5.96139417  5.88790924  5.84161805 12.07509932\n",
      "   8.17204359  6.8440686   8.81592306  7.08803441  7.22555726  8.88650669\n",
      "   6.13406239  6.15462111  4.15862062  6.37164158  3.56642471         nan\n",
      "          nan         nan]\n",
      " [ 5.84221427  6.78405974 10.45956196  6.19514392 10.36033197  6.93605285\n",
      "   7.00998471  3.96814743  6.36566054  5.83187993  8.03692905 16.86103267\n",
      "   4.96764418  4.3024804   3.56170653  7.96363152  2.5075037   4.29159833\n",
      "   3.37802737         nan]\n",
      " [ 5.50172249  4.01996341  3.74759091 10.51724941  7.06399573  5.49264959\n",
      "   4.40485005  4.49972509 19.40527797  3.41708564  5.87445596  6.03701614\n",
      "          nan         nan         nan         nan         nan         nan\n",
      "          nan         nan]]\n",
      "[[-2.900e-01 -6.000e-02  2.800e-01  1.620e+00  3.000e-02 -2.100e-01\n",
      "   1.080e+00  8.400e-01 -1.320e+00  9.670e+00  0.000e+00  2.800e-01\n",
      "   1.250e+00  9.020e+00  6.940e+00  5.510e+00 -2.120e+00  0.000e+00\n",
      "   8.500e-01  1.020e+00]\n",
      " [-1.500e-01  2.100e-01  6.000e-02  1.013e+01  2.700e-01  3.700e-01\n",
      "  -4.090e+00  2.300e-01  8.500e-01 -4.600e-01  0.000e+00 -7.600e-01\n",
      "  -7.500e-01  3.310e+00  5.910e+00  5.190e+00  1.500e+00  0.000e+00\n",
      "  -5.100e-01  2.850e+00]\n",
      " [ 1.380e+00 -3.000e-01 -5.200e-01  6.700e-01 -1.020e+00 -6.100e-01\n",
      "   4.150e+00  2.255e+01  8.110e+00 -4.500e-01  0.000e+00  8.130e+00\n",
      "  -4.000e-01  2.700e-01  5.840e+00  4.500e-01  2.200e-01  0.000e+00\n",
      "  -2.700e-01  1.600e-01]\n",
      " [ 2.400e-01 -7.000e-02 -3.700e-01 -9.000e-01 -4.000e-02  1.400e-01\n",
      "   5.830e+00 -4.600e-01  7.300e-01  1.392e+01  0.000e+00 -2.510e+00\n",
      "  -9.500e-01  4.510e+00  2.020e+00 -1.850e+00  1.440e+00  0.000e+00\n",
      "  -6.400e-01 -6.300e-01]\n",
      " [-3.100e-01  8.950e+00  1.207e+01  9.910e+00  1.400e-01 -3.000e-02\n",
      "   1.360e+00  5.900e-01  6.840e+00  3.900e-01  0.000e+00 -9.100e-01\n",
      "   5.400e-01 -1.970e+00 -6.400e-01  1.390e+00  1.146e+01  0.000e+00\n",
      "   3.700e-01  4.200e-01]\n",
      " [-3.480e+00  5.100e-01  9.900e-01 -1.200e+00  2.470e+00  1.320e+00\n",
      "   2.230e+00  8.590e+00 -4.100e-01 -2.560e+00  0.000e+00  7.950e+00\n",
      "   1.090e+00  5.100e-01  2.060e+00 -3.600e-01 -1.080e+00  0.000e+00\n",
      "   7.400e-01 -1.200e-01]\n",
      " [ 1.020e+00 -2.200e-01 -3.600e-01  4.700e-01  6.720e+00  1.336e+01\n",
      "   1.500e+00 -1.800e+00  3.200e-01  5.000e-02  0.000e+00  3.620e+00\n",
      "  -2.500e-01 -9.000e-02 -2.700e-01  3.100e-01  1.000e-01  0.000e+00\n",
      "  -1.700e-01  1.300e-01]\n",
      " [ 1.162e+01  1.800e-01  3.000e-01 -4.100e-01  6.700e-01  1.208e+01\n",
      "  -1.400e+00  1.550e+00  8.820e+00 -2.000e-02  0.000e+00 -3.150e+00\n",
      "   2.100e-01  4.000e-02  2.400e-01  6.370e+00 -8.000e-02  0.000e+00\n",
      "   1.400e-01 -1.100e-01]\n",
      " [ 6.500e-01  6.780e+00  1.046e+01 -7.700e-01 -3.700e-01 -9.000e-02\n",
      "  -9.900e-01 -1.270e+00  9.100e-01 -7.500e-01  0.000e+00  1.880e+00\n",
      "   4.970e+00  4.300e+00  9.300e-01  7.960e+00  1.300e+00  0.000e+00\n",
      "   3.380e+00 -5.500e-01]\n",
      " [-1.290e+00  6.300e-01  8.000e-01 -2.220e+00  1.010e+00  6.600e-01\n",
      "   4.400e+00  4.500e+00  1.100e+00  3.420e+00  0.000e+00  2.730e+00\n",
      "  -1.400e-01 -2.300e-01 -2.900e-01 -2.950e+00  1.100e+00  0.000e+00\n",
      "  -1.000e-01 -9.600e-01]]\n",
      "[[-2.86649118e-01 -6.07720760e-02  2.79647732e-01  1.62189219e+00\n",
      "   3.27593813e-02 -2.06305928e-01  1.08496512e+00  8.38502116e-01\n",
      "  -1.32339096e+00  9.66535034e+00  0.00000000e+00  2.81615782e-01\n",
      "   1.25410067e+00  9.01607959e+00  6.94348475e+00  5.51480273e+00\n",
      "  -2.11696980e+00  0.00000000e+00  8.52795856e-01  1.01537410e+00]\n",
      " [-1.45293209e-01  2.08630212e-01  5.92559401e-02  1.01286226e+01\n",
      "   2.71447591e-01  3.68579624e-01 -4.09299256e+00  2.31985743e-01\n",
      "   8.48657186e-01 -4.60066104e-01  0.00000000e+00 -7.59679624e-01\n",
      "  -7.53790387e-01  3.30979458e+00  5.91122279e+00  5.18522696e+00\n",
      "   1.49827189e+00  0.00000000e+00 -5.12581912e-01  2.85037109e+00]\n",
      " [ 1.37992645e+00 -3.01032888e-01 -5.15308306e-01  6.70012883e-01\n",
      "  -1.02287566e+00 -6.07496512e-01  4.14847893e+00  2.25529973e+01\n",
      "   8.10691122e+00 -4.54387044e-01  0.00000000e+00  8.12702122e+00\n",
      "  -3.96219478e-01  2.66524193e-01  5.84053843e+00  4.48363827e-01\n",
      "   2.21965117e-01  0.00000000e+00 -2.69431584e-01  1.61298920e-01]\n",
      " [ 2.38722957e-01 -7.15818958e-02 -3.66539783e-01 -9.00689857e-01\n",
      "  -4.34435791e-02  1.44586337e-01  5.82595691e+00 -4.56219030e-01\n",
      "   7.29019649e-01  1.39212917e+01  0.00000000e+00 -2.50608038e+00\n",
      "  -9.46685467e-01  4.50858906e+00  2.01736479e+00 -1.84597533e+00\n",
      "   1.44357431e+00  0.00000000e+00 -6.43751705e-01 -6.27190198e-01]\n",
      " [-3.09982058e-01  8.95221534e+00  1.20709072e+01  9.91254260e+00\n",
      "   1.38736194e-01 -3.21830834e-02  1.35601304e+00  5.87240362e-01\n",
      "   6.84179351e+00  3.85470937e-01  0.00000000e+00 -9.10224516e-01\n",
      "   5.38748270e-01 -1.97418214e+00 -6.41756999e-01  1.38767752e+00\n",
      "   1.14569095e+01  0.00000000e+00  3.66352003e-01  4.20895661e-01]\n",
      " [-3.47834092e+00  5.06202534e-01  9.85929952e-01 -1.20385136e+00\n",
      "   2.47351011e+00  1.31857730e+00  2.22868701e+00  8.58980522e+00\n",
      "  -4.14627456e-01 -2.55584335e+00  0.00000000e+00  7.94544076e+00\n",
      "   1.08981723e+00  5.07814789e-01  2.06070470e+00 -3.62180792e-01\n",
      "  -1.08088039e+00  0.00000000e+00  7.41082151e-01 -1.22600834e-01]\n",
      " [ 1.01622020e+00 -2.16339661e-01 -3.61198028e-01  4.66484697e-01\n",
      "   6.71917272e+00  1.33561722e+01  1.49697658e+00 -1.79952700e+00\n",
      "   3.23928753e-01  5.02925507e-02  0.00000000e+00  3.61618360e+00\n",
      "  -2.50873701e-01 -9.26709962e-02 -2.74050483e-01  3.14867593e-01\n",
      "   9.87452833e-02  0.00000000e+00 -1.70595597e-01  1.26352961e-01]\n",
      " [ 1.16175802e+01  1.76618799e-01  2.96812474e-01 -4.06166177e-01\n",
      "   6.70013881e-01  1.20750994e+01 -1.40373758e+00  1.55371195e+00\n",
      "   8.81592302e+00 -1.92925050e-02  0.00000000e+00 -3.14647245e+00\n",
      "   2.09283062e-01  3.53492550e-02  2.40740979e-01  6.37164153e+00\n",
      "  -8.34150082e-02  0.00000000e+00  1.42313718e-01 -1.09670824e-01]\n",
      " [ 6.45897707e-01  6.78405976e+00  1.04595620e+01 -7.71818926e-01\n",
      "  -3.74925210e-01 -9.34266564e-02 -9.92231843e-01 -1.27177959e+00\n",
      "   9.12572164e-01 -7.49648203e-01  0.00000000e+00  1.88241254e+00\n",
      "   4.96764418e+00  4.30248058e+00  9.30710574e-01  7.96363134e+00\n",
      "   1.29767786e+00  0.00000000e+00  3.37802736e+00 -5.52484848e-01]\n",
      " [-1.29123339e+00  6.29698333e-01  7.97496857e-01 -2.22331961e+00\n",
      "   1.00958752e+00  6.58123180e-01  4.40484609e+00  4.49972602e+00\n",
      "   1.10355721e+00  3.41708755e+00  0.00000000e+00  2.72906028e+00\n",
      "  -1.41913533e-01 -2.25419385e-01 -2.88662351e-01 -2.94923642e+00\n",
      "   1.09722636e+00  0.00000000e+00 -9.65020398e-02 -9.62723053e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# getting the treat unit-times\n",
    "observedset = np.argwhere(~np.isnan(Yobs))\n",
    "o_idx = np.random.choice(list(range(observedset.shape[0])), size = int(observedset.shape[0]/5), replace=False)\n",
    "\n",
    "# Initializing the MC-NNM object\n",
    "my_mcnnm = MatrixCompletion_NNM(setOk=tuple(observedset[o_idx].T), \n",
    "                                lamb=10, epsilon=10**(-6), doprint=True, max_iters=200, printbatch=20)\n",
    "\n",
    "# Fitting (/transforming)\n",
    "Lest = my_mcnnm.fit_transform(Yobs)\n",
    "\n",
    "print(Lest)\n",
    "plt.imshow(Lest, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.669331008634215"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total loss on the full sample\n",
    "mcnnm_loss(Yreal, Lest, tuple(observedset.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.97205741e+01 2.62459518e+01 2.18879134e+01 2.14571653e+01\n",
      " 1.61319666e+01 1.45697133e+01 1.29247231e+01 2.12134359e-15\n",
      " 1.54409409e-15 7.58049933e-16]\n",
      "15.350839929591562\n"
     ]
    }
   ],
   "source": [
    "U, Sigma, VT = np.linalg.svd(Lest, full_matrices=False)\n",
    "print(Sigma)\n",
    "print(np.median(Sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical strategy of cross-validation is to split the rows of the data (X,y) to have specific folds (X_k, y_k) which are used to fit the model, and are then evaluated on the left-out fold (X_k', y_k').\n",
    "\n",
    "In this case, it is a bit different, because the prediction is the matrix itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation, and as a consequence the estimate, will depend on the value of $\\lambda$. As a hyper-parameter, we will choose its value through cross-validation.\n",
    "\n",
    "Athey et al. propose to use some sort of $K$-fold cross-validation, and choose $K$ such that \n",
    "$$\\left|\\mathcal{O}_k\\right|/\\left|\\mathcal{O}\\right| = \\left|\\mathcal{O}\\right|/(NT).$$\n",
    "That is, such that the fraction of non-missing values in a given validation set $\\mathcal{O}_k$ is equal to the fraction of non-missing values in the original matrix. We will do this making use of Grid Search. \n",
    "\n",
    "This obviously assumes that we have access to the real matrix in which we can actually observe the supposed ''missing'' values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcnnm_kfold_CV(Yreal, Yobs, observedset, lambda_cv, num_splits=10):\n",
    "    kfold = KFold(n_splits=num_splits, shuffle=True)\n",
    "    vec_errors = np.zeros(num_splits)\n",
    "    for i, train_test_tuple in enumerate(kfold.split(observedset)):\n",
    "        O_train_i = tuple(observedset[train_test_tuple[0]].T)\n",
    "        O_valid_i = tuple(observedset[train_test_tuple[1]].T)\n",
    "\n",
    "        # Initializing the MC-NNM object\n",
    "        my_mcnnm_i = MatrixCompletion_NNM(setOk=O_train_i, \n",
    "                                    lamb=lambda_cv, epsilon=10**(-6))\n",
    "\n",
    "        # Fitting (/transforming)\n",
    "        Lest = my_mcnnm_i.fit_transform(Yobs)\n",
    "\n",
    "        # Error on validation set\n",
    "        vec_errors[i] = mcnnm_loss(Yreal, Lest, O_valid_i)\n",
    "        \n",
    "    return vec_errors\n",
    "\n",
    "def mcnnm_GridSearch(Yreal, Yobs, observedset, lambda_vec, num_splits=10, doprint=True):\n",
    "    mat_errors = np.zeros((len(lambda_vec), num_splits))\n",
    "    for i, lambda_cv in enumerate(lambda_vec):\n",
    "        mat_errors[i,:] = mcnnm_kfold_CV(Yreal, Yobs, observedset, lambda_cv, num_splits=num_splits)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_results = pd.DataFrame(mat_errors,\n",
    "                             index = [\"Lambda = {}\".format(np.round(l, 2)) for l in lambda_vec],\n",
    "                             columns = [\"Fold {}\".format(i+1) for i in range(num_splits)])\n",
    "    \n",
    "    vec_rmse = df_results.mean(axis=1)\n",
    "    best_lambda = lambda_vec[np.argmin(np.array(vec_rmse))]\n",
    "    \n",
    "    if doprint:\n",
    "        print(\"\\nMatrix of errors:\")\n",
    "        print(\"-----------------\")\n",
    "        print(df_results)\n",
    "        print(\"\\nAverage RMSE across folds:\")\n",
    "        print(\"--------------------------\")\n",
    "        print(vec_rmse)\n",
    "        print(\"\\nBest parameter value (returned):\")\n",
    "        print(\"--------------------------------\")\n",
    "        print(np.round(best_lambda, 3))\n",
    "    \n",
    "    return best_lambda\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda vector:[  1.1         31.56896552  62.03793103  92.50689655 122.97586207\n",
      " 153.44482759 183.9137931  214.38275862 244.85172414 275.32068966\n",
      " 305.78965517 336.25862069 366.72758621 397.19655172 427.66551724\n",
      " 458.13448276 488.60344828 519.07241379 549.54137931 580.01034483\n",
      " 610.47931034 640.94827586 671.41724138 701.8862069  732.35517241\n",
      " 762.82413793 793.29310345 823.76206897 854.23103448 884.7       ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating my data\n",
    "N, T = (30, 40)\n",
    "Yreal = np.array([[np.random.exponential(scale = 2, size = 1)[0] + ((T-j)**0.75)*np.log(N-i+1) for j in np.arange(T)] for i in np.arange(N)])\n",
    "\n",
    "# specifying the units treated, and the earliest time of treatment\n",
    "tr_units = np.arange(int(N/3),N)\n",
    "t0 = int(T/2)\n",
    "\n",
    "# -------------------------------------------\n",
    "Yobs = stag_adopt(Yreal, tr_units, t0)\n",
    "plt.imshow(Yobs, cmap=plt.cm.gray);\n",
    "\n",
    "observedset = np.argwhere(~np.isnan(Yobs))\n",
    "\n",
    "# Specifying a set of values for lambda from a SVD on the Yobs with missing=0\n",
    "U, Sigma, VT = np.linalg.svd(PO_operator(Yobs, tuple(observedset.T)), full_matrices=False)\n",
    "lambda_values = np.linspace(1.1*np.min(np.floor(Sigma[Sigma>0])),\n",
    "                            0.9*np.max(np.floor(Sigma[Sigma>0])), \n",
    "                            num=30)\n",
    "print(\"Lambda vector:{}\".format(lambda_values))\n",
    "\n",
    "# Creating GridSearchCV-type objects\n",
    "tuned_parameters = [{'lamb': lambda_values}]\n",
    "n_folds = 5\n",
    "myfunction_loss = make_scorer(loss, setO=tuple(observedset.T), greater_is_better=False) # I don't use this...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lamb = mcnnm_GridSearch(Yreal, Yobs, observedset, lambda_values, num_splits=n_folds, doprint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\t Current loss: 3.2945698893333275\n",
      "Iteration 20\t Current loss: 1.8940034928867089\n",
      "Iteration 40\t Current loss: 1.8940034928841394\n",
      "Iteration 60\t Current loss: 1.8940034928841392\n",
      "Iteration 80\t Current loss: 1.8940034928841392\n",
      "Iteration 100\t Current loss: 1.8940034928841392\n",
      "Iteration 120\t Current loss: 1.8940034928841392\n",
      "Iteration 140\t Current loss: 1.8940034928841392\n",
      "Iteration 160\t Current loss: 1.8940034928841392\n",
      "Iteration 180\t Current loss: 1.8940034928841392\n",
      "Iteration 200\t Current loss: 1.8940034928841392\n",
      "\n",
      "Final values:\n",
      "Iteration 200\t Current loss: 1.8940034928841392\n",
      "\n",
      "[[55.39912753 54.59487507 53.44175332 ...  8.24696806  9.44388875\n",
      "   4.24279375]\n",
      " [54.58323038 53.59248932 55.40833455 ...  9.74931152 14.0394379\n",
      "   6.42703165]\n",
      " [54.2316932  56.06311479 54.26878396 ... 11.7848737   8.19022058\n",
      "   7.35675704]\n",
      " ...\n",
      " [22.21878438 24.02347    22.26868028 ...  4.40378018         nan\n",
      "          nan]\n",
      " [19.78547952 19.84341188 18.23522072 ...         nan         nan\n",
      "          nan]\n",
      " [16.68734349 11.59636967 11.02917899 ...         nan         nan\n",
      "          nan]]\n",
      "[[55.93 55.23 54.78 ...  9.85  8.65  5.55]\n",
      " [54.97 54.28 53.83 ...  9.68  8.51  5.46]\n",
      " [54.86 54.17 53.73 ...  9.66  8.49  5.44]\n",
      " ...\n",
      " [23.67 23.38 23.19 ...  4.17  3.66  2.35]\n",
      " [20.3  20.05 19.88 ...  3.57  3.14  2.02]\n",
      " [13.36 13.2  13.09 ...  2.35  2.07  1.33]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8940034928841392"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the MC-NNM object\n",
    "my_mcnnm = MatrixCompletion_NNM(setOk=tuple(observedset.T), \n",
    "                                lamb=best_lamb, # <------ best value!\n",
    "                                epsilon=10**(-6), doprint=True, max_iters=200, printbatch=20)\n",
    "\n",
    "# Fitting (/transforming)\n",
    "Lest = my_mcnnm.fit_transform(Yobs)\n",
    "\n",
    "# total loss on the full sample\n",
    "mcnnm_loss(Yreal, Lest, tuple(observedset.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACVCAYAAABIDAHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAGntJREFUeJztnVuMXdV5x/+fjbkYg+82BgabWhbiVhJRpUitRJUUieaFPKRSeKj8gMRLKiVSHmK1UqW+0Zf0pX2xFASVoqSXRMIPEQUhoqhSRRhRMFdfGBvfxh4bDJir8czqg4+PvvWfM+s7a86Zfc5s/j/J8v7O3nutb6+9zpp9/vtb37KUEoQQQix/VozaASGEEMNBA7oQQrQEDehCCNESNKALIURL0IAuhBAtQQO6EEK0BA3oQgjREjSgCyFESxhoQDezh83sgJkdNrM9w3JKiFGjvi2WI7bYmaJmthLAQQAPATgB4GUAj6aU3hqee0I0j/q2WK5cNcC53wJwOKU0BQBm9isAjwBYsNNv3LgxTUxMdG3+Y1Lzx2V2djazr7766sz+4osvFix7xYoVC+7rVfbc3Fxm8/n+eC7rqqvyJv7qq6+KdXlWrlyZ2ZcuXSqeG7Wfvw4+lq+J62JKfvM+LtvMMvvLL79c0E/2lc/17Tk3N4eUUn7A4qjq25s2bUo7duxYsDDvf9Tna78TpfsQlcXtzJT215bt90f11pTF9iB+Rftry2a79H2NxqDZ2dlzKaXNCBhkQL8FwHFnnwDwp6UTJiYm8Nxzz3Vtdpq/nB4eGN9///3M3r59e2YfPHgws/2gcd1112X72I/z588veC4AXHvttZn98ccfd7d5wN60aVNmnzlzJrM/+uijzPbXvX79+mzfuXPniudGg/CFCxcW9HP16tWZ/cEHH2Q2t5Evq1RPr7L5D9WRI0cy+/PPP89s/8d51apV2b6ZmZnu9ieffLKgT5VU9e0dO3ZgcnKya5ceCPhBg4/le3jx4sXM5j9ovq35XP4O8f7PPvuseLz3lfexX7yf74U/ns/lwYz7JpdV8oXL5mvmvsU2f9e9L9E1+3Gg1/Effvjhgr7xNfN3+/33338PfTCIht7rSWje44SZPW5mk2Y2yYOwEGNK2Ld9vz579mxDbglRZpAn9BMAJpx9K4BTfFBKaS+AvQBw3333Jf9Ewn+V/JMv/2XlJ0b+qz41NZXZ11xzTWb7v5b8lMNP//xEyX+JuWz/V52PPX78eGZzXfyE5p9A/dNnr3r5Cf706dOZze1b+onHT0HsFz/NMf5Jh6+Rnzb4KYif2Pn++OvesGFDts/7HflYQdi3fb++//77k++vpSf0SDbj/Wxz2/Rbbz9ll46vlSV7SAYL7ovKjn55+rpr/RqmnMPUHB/JUP0yyBP6ywB2mdntZnY1gB8A2DcUr4QYLerbYlmy6Cf0lNIlM/tbAP8NYCWAJ1NKbw7NMyFGhPq2WK4MIrkgpfRbAL8dki9CjA3q22I5MtCAXktKKdOwrr/++my/12H5jTHDenIU4eA1Ko7C4LfRa9asyWzWLTlSxYfl3XjjjUW/uG7W1fx18VtxLmvt2rWZzdE37Ldvb9axObKHde2tW7dm9qlT+esSr5tzJApHFU1PTxf95Dbx5/O5vl4up0n61VqHvUJYKRS1Sca17kG16eW2opum/gshREvQgC6EEC2hUckFyMOGWFLgn+oeDl3iCRocosf7o9CnhXwE5ksdPPPRTx5iKSKavMEhfn7yEB/L4ZQc1sh+s6zi2yAq+9NPP81sjrUuhd9x+/C9ie4lX4cPe2R5zEtzpVmTS0lKKbuGmolFUWhhNLHI74/CAbmsaKKM3x+VxXXzft8HSuG0vfZzm/DxpQk6NeGUveqqCQuttWtm+faLntCFEKIlaEAXQoiWoAFdCCFaQuMaekkb8vrXunXrsn2cmIq1RNaAWZv2WjaHREaZGrku1r68lh2lFdi1a1dmv/baa5ntQws5lJD9YiLdzYc1sr7OeXZKGSV77ffvPziklN8j8L3i6+I28yGUfOzGjRu725z6oElK4ZNeO41SP0TZOqP+VVNWlHLB32Mui89leH/pHUuU+TM63vvN9UZll66Zy+N7xefWhs1yXcNAT+hCCNESNKALIURL0IAuhBAtofGp/6V4cD/1P4rh5HI4brpUTxSzHunFpeNLKYEB4JVXXin6WYpN5dheJprm7LVs9jNKpcDXwdP5vQYfLY7B17Fz587MPnr0aGb78ri9Sgs8NMXc3FzWtqV45Wh1Jr4GPr7UF6N0uOxX1O/9feKyopW3SjHvUT/msqO49VIcehRnPsw49Kj9mVLaBsWhCyHE1xwN6EII0RI0oAshREtoVENfsWJFFmfNsc8+5pPTzEa6dmlZOCCPwY3icXnh2CjnhdfONm/OF+Y+efJkZm/bti2zeYk6f11RjCzvZ02UF6j28fKlOOFecCw52/5+cftwSmHO4XPixInM5vchW7Zs6W7zfASvNUZx+kuFmRVjtvnYGju6596O4pr5vtTUFfnBlPbXnltzfG371tRdG2c+SDrnxZ6rJ3QhhGgJGtCFEKIlaEAXQoiW0Hgul5LOV8rtzHHQPkd2r+NZL/S6bJTjgvV31oBZx/W5STifCGv7nMO8lHOG/Vy/fn1msxbNbct1+faN4nH5mjm+l98z+PblvPY33XRTZh87diyzo7wgvr1LOd5HBS+tWOqLg+bQZvz+qC0GqZv7Yo1ffH4Uc106N7KjsoZZdsQgseWKQxdCiK85GtCFEKIlaEAXQoiW0KiGPjs7m+m+JY2JdchonUHW2B988MHM3rdvX3ebdbRo/VHOn85atd/PfrLmyzlQWI/3+zkem+P2OY87+11aX5E18jVr1mT24cOHi2WxbwvVAwD79+/PbH4XwO9DStfF+rzvJ4PE/Q5KvxrxoBpvKdd6yad+6h7E7xq9uEa3rq17sdpzP+dH1zwO6AldCCFaggZ0IYRoCY1KLnNzc1m4G8sqN9xwQ3ebp9v7pcaA+SlaWRZ59tlnF/SDJZO1a9dm9pkzZzLbpysA5ocD+tDEKKyOl5VjSpIUtwm3X7RcmZcyuP1OnTqV2aU0okB5iTqWsPjY2qX1fN0cBurv+6h+As/NzWX3fZjpc/me8z0thfqW0sz2skspcqOyovS63uZ9TORnyZfadLk1dq1cFkk0pXBWhS0KIcTXHA3oQgjREsIB3cyeNLMZM3vDfbbBzJ43s0Od/9eXyhBiHFHfFm2jHw39KQD/AuDf3Gd7ALyQUnrCzPZ07J9GBZlZMbTMa6usIXGaWQ67Y12Ww9v8lHrWJVnj5bo5rI7L9su1cVkcgsfhlWx7LZv1P54iz35w3aWlvlgrZG06mkbO1+V1cH4nwSkK1q1bl9kcusn462IN2rfBIsIWn8KQ+naJYaZRrUnvOsqwupr0uYP6OUiq3nFlydLnppR+D+AD+vgRAE93tp8G8L1F1S7ECFHfFm1jsRr61pTSNAB0/t8SHC/EckF9WyxblvylqJk9bmaTZjYZhewJsVzw/ZpDQIUYFYuNQz9jZttSStNmtg3AzEIHppT2AtgLAHfffXcmlpWWlfO6NFBOhwvMjxVnfIw2a8scw856Mi+Hx5qfP561ZY5pZ52b9WOvRUexv9wGfHwppQH7ydp0SSMH5uv5/v7wALdhw4bM5vS50VRvv2wft6dPlcDvOhZJX33b9+t77703+djqUhx6KR0DEKdvYG21VC+3Y5Q+o+RLbRx6Kf47ikOPYsPZl1Lq4sgeJFZ8kLjzXnbp3H5Z7BP6PgC7O9u7ATyzyHKEGDfUt8WypZ+wxV8C+F8Ad5jZCTN7DMATAB4ys0MAHurYQiwr1LdF2wgll5TSowvs+s6QfRGiUdS3RdtoNJcLL9XFlJbTYs12+/btmT01NZXZrDV6jbgURw4AExMTmf3WW29ldilPRaSbsVZdag/ex6l3uSx+N1DKUcN5X7hN+Br5eF6CbvPmzd1t1shr0/7yu4FSqt5S+zVJv1rroEvQldLn1qa0HWQJukFT3g6zrJrl7WrrLrVBRBNLzjGa+i+EEC1BA7oQQrQEDehCCNESGtXQgVyTYh3WL4PGuiprhxwbzrHjrCdv3bq1uz09PZ3tY734nXfeKe4v5QJnrZl17yjO2JfNWjPnhOc24Lr53UApzp/bj2O6uWxuA6+T8zVzWVG+a75uXx7n9PHx8aPU04eloddoz3x8KT67n7pqlqAbZCm9Yervg5Zdq7kv9tim0BO6EEK0BA3oQgjREjSgCyFES2hUQ5+dnc20W9b4fN5sjjtnTZzXwOSYbK+ZA8CJEye621EuCa6b9eOS7u3XRQXyPOzA/HjvElE8NvvB+Va4Lv8eIsr57t9n9Cqb32mU3iPU5LAA5ud+4Vw7ntWrV3e3S/nfl5KaNUWjdWHZjnK5+Hqjduay2ZeaNUWjc0vvSWrXFK1ZK3WQNUN72aW5MUzt+5HSPq0pKoQQX3M0oAshREtofOq//6nG0ob/ucMhjfxzh8Pm+OcNp3D15/PydSdPnsxsnjLPsgmHD/op9SwFcVm85Bz7WfMzlyUVtjkU0cNhi/xTk/dzemKWaHz7sx8s37CEwmGKp0+fzmzfT0rtN6qwxZRS8Wd/KX1ulJY2Ct8tpY6Nyo7CGv3+2jDFkpQRSW7jlOK2JH3Ulj1IWGi/6AldCCFaggZ0IYRoCRrQhRCiJTQ+9d9rgD7lKgCcPXu2u806LIclsj7Mmi/rzd5mHXPXrl2ZzZo66/Wsk3t9mfVhf01APM3dhyZGx7K2z/pq1Cb9+gHMT4HLeuHOnTu726+//vqC9QDzNfWZmXyVN9YPfV/ge+f9HlXYItB/GttazbYm/euwp70v1dT/mqn8/dQ1zDaIfKlhFKkB9IQuhBAtQQO6EEK0BA3oQgjREhqPQ/dTyDne2Ou2rFuXNHEgjlP3ui3rwax1nTt3LrOjNLZec/daMgC8+eabmc3af+ldAGvi0dT/KH0ul+fhdxQc7x1NkT5y5MiCZfO9Yb8i/dWnhGA/x4GUUnHqv+9fg0yZ74UvryauHJjff/h4X3YU0x7VVYrTZ4Y59T8qK2ozb9ccW2trCTohhBAZGtCFEKIlaEAXQoiW0LiG7nU71nR9vDHHc0dpRHk/69x+2bnaVKB8/Pnz5xc8/9ChQ9k+zhvDmh7r+V4H56Xc2M877rgjs48dO5bZfB2+PG4/To/L7R+1ye23397d3r9/f7aP486juOKSbjyOy36llPrOqTKI9gwMlsulJt8KH1+7vF1pf20+lZpY/UFztdQsH1i7VF4J5XIRQgiRoQFdCCFaggZ0IYRoCY1r6F4b8vHFV/ZfgTW4TZs2ZTbnEWc430opD7vPZw7MXwKN4+U5xt1r0+w350PnvCW8VJ6P5+b3AqyhHzhwILO5bo6f9+ezZh7F8XP8N5f97rvvLugHx53zuwG2+d6Vls4rxUo3xTDj0GuXoPPlDboEHbdfKTd/FMPO/ckfz/uiGPeaJetq48xrYsuj9wiDvAtQHLoQQoiMcEA3swkze9HM3jazN83sR53PN5jZ82Z2qPP/+qV3V4jhob4t2kY/T+iXAPwkpXQngAcA/NDM7gKwB8ALKaVdAF7o2EIsJ9S3RasINfSU0jSA6c72BTN7G8AtAB4B8Bedw54G8DsAPy2VtXLlyiwmmXVZr22X1toE5utsvAZpSR/keks5LID5enMpzwznU+F86FHecV9XlPNi9erVxbrWr88fLP06oFw2rxl64cKFzOb3Dvye4fjx491tzgNTys0CzG8zjt33cf8+3h0ADh8+3N2uzYc+rL49NzeX9b+Slhppz4No6JGm22Qul9L3tUYTB+quKzq3NrdLTZz/IGuhjiQO3cx2APgmgJcAbO18Ia58MbYsygMhxgD1bdEG+h7QzWwNgF8D+HFK6ePoeHfe42Y2aWaTvFK8EOPAYvq2+rUYR/oKWzSzVbjc4X+RUvpN5+MzZrYtpTRtZtsAzPQ6N6W0F8BeANixY0fy09P5J8kNN9zQ3eafRkePHs1sDnWLflp5mYSPZQmmlGa21/n+OjhEj+Gfm7yMnA9z5PZhWSmaasxpgL2cw7IIpyC45557MntycjKz33vvvcz218USShTyyPeSUyv4+zE1NZXt8+mHuX36YbF92/frnTt3Jt+2pZ/aUdhiJF2UUjZEP/H5O8H3pSZsMZJc+Dp9WTXpcPnc6PhayaXGjlIZDzNscckkF7vcg34O4O2U0s/crn0Adne2dwN4ZlEeCDEi1LdF2+jnCf3PAPwNgNfN7NXOZ38H4AkA/2FmjwE4BuCvl8ZFIZYM9W3RKvqJcvkfAAtpEN8ZrjtCNIf6tmgbjU79n5uby3Q71ol4ir0n0tF4P4caejgEL9Ito7r9+T4FMDA/DW0p7AzINfhII2c/WBPl8Epe7q7kl5/KD+TvN4A8BJLPj3RJ9quk9QN5+l1uz1J/aoq5ubks/LSknUahgtEUer5P/r1B7RJokZ5fo6Hzfr6HXsuOwhajFAWlUM/ou1rS9oHBNPRBlreL3n/0i6b+CyFES9CALoQQLUEDuhBCtIRGNXQzy/RTjtlet25dd5v1J45tjpaoYw3Ka42sc5f0dqBuSjlP5ed4b55SH8XklvxgTZy1afbFpwpgPzjNr1+yr5efjK+bY+tZe+RUyPzuhK/Lx6XzNfp7N8r0ub7/lfTQKH67Zjk+3h/psFFMdun4qKwau9bPqO+VptDXLF/Xz/GlY2vrGkkcuhBCiOWBBnQhhGgJGtCFEKIlNKqhX7p0KUuL6zVzIF96jFO/cmpY1sxZZ+OyvYbO57Iuy3o9a/2l1Lys/0ZpaPl4rz+zFn3zzTdntl+uDpgfK84aqX/vEOmn/J6B/eY28L7yewPW50+ePJnZrD1y+/v7E2nKoyCl1PdScINq6ByH3q92D8Tx3cwgceilnCo12n0vu1RXbe6WmiXqauP8azR1LUEnhBAiQwO6EEK0BA3oQgjREhrP5eL1aNamvb7F+6L8K5s3b85sXubMxzKzPsxa9caNGxf0C4hj4j0cC851836fK5w1Ts4Tzvof50ThNvJ5T1iL5XzokZ/cZr5NuL04dzovI3fgwIHMLuXbYD3e+1G6D0vJ7OxsVndJS63J79HreKYUhx/FWJfeBQHlnCvRdXDZJQ09Kjvys6Sh1yyN18uu8bt2ebtSLpcoj9NC6AldCCFaggZ0IYRoCRrQhRCiJTSqobPWuHXr1my/182jPOKsR3Gcus+hzedzLm8u6/jx45ntc6AA8zU8H3fNWjRr/7zuJdddyqsdwTlpOJafdW9PpCXyO4mSb5FOefDgwczmNuDzfRvyveP3GaMg0tB9f4lygUcaOn8P/HuRqL9E7RzFkpfKivKOl3LORGXXrMMa6dZRPy+1f3TNUV3Khy6EEKJvNKALIURLGKnkwj+lvGQQLdXVq2wPh/j5n+3RTzhOG8BLu/HP/JmZme42yxw+1UEvP0thaVwWp7SNponz8d5vboPoGqOfqlu2bOluczpcTq0QlVVK61BKEbzYUK9BmZ2dzfpbKXwwCquLfsaXljCMrj/qL0spuZRkkcjPKEVBqezommpCDaOw0CgdSam9o37RL3pCF0KIlqABXQghWoIGdCGEaAmNT/0vpYf1Gvptt92W7ZuamsrsnTt3ZjaHGnJ4m089yyGOnHaW09IyrG17jY9Tw7I2zRowa2W+DVh/Ly2/BszXV1mz8+GVrNlxWTz136ck6OWL9zUq+/rrr89sDu3kunwblZa3G9USdJcuXcrCOkt+RBpv7RTwmuURIw29pu5IBy9p1dF9irRnpkZDr106rxRayNRO/fe+KWxRCCFEhgZ0IYRoCRrQhRCiJTQeh+6XZPPx21f2X4F1bF7WjJd243S7vLTb/v37u9usdbEfHIPNOjhP3/caMetkrAezn6xF33jjjd1tTlkbpQhmP1mrPnPmTHe7tPQdML8NWKvl+1Ga0s77eI4Ap1bg9vXnc3vyNY+Cixcv4ujRo127RkNnoljnUnmRHs/ULplW2lezHFt0TZHuzZTKHsRPPr92LkxN3H/tNS+EntCFEKIlaEAXQoiWoAFdCCFagjUZu2tmZwG8B2ATgHPB4aNAftUxbn5tTyltjg8bLurXi0Z+9U9ffbvRAb1bqdlkSulPGq84QH7VMa5+jYpxbQ/5Vce4+tUPklyEEKIlaEAXQoiWMKoBfe+I6o2QX3WMq1+jYlzbQ37VMa5+hYxEQxdCCDF8JLkIIURLaHRAN7OHzeyAmR02sz1N1t3DlyfNbMbM3nCfbTCz583sUOf/9aUylsCnCTN70czeNrM3zexHY+LXtWb2BzN7rePXP3Y+v93MXur49e9mdnVUVlsZl749jv2644P6dgM0NqCb2UoA/wrgrwDcBeBRM7urqfp78BSAh+mzPQBeSCntAvBCx26SSwB+klK6E8ADAH7YaaNR+/UlgG+nlO4D8A0AD5vZAwD+CcA/d/w6D+Cxhv0aC8asbz+F8evXgPp2IzT5hP4tAIdTSlMppYsAfgXgkQbrz0gp/R7AB/TxIwCe7mw/DeB7Dfs0nVJ6pbN9AcDbAG4ZA79SSulKVrFVnX8JwLcB/Neo/BojxqZvj2O/BtS3m6LJAf0WAH5ZoROdz8aJrSmlaeByBwSwJTh+yTCzHQC+CeClcfDLzFaa2asAZgA8D+BdAB+mlK6kkBvH+9kU4963R95/POrbS0eTA7r1+EwhNj0wszUAfg3gxymlj0ftDwCklGZTSt8AcCsuP5He2euwZr0aG9S3+0R9e2lpckA/AWDC2bcCONVg/f1wxsy2AUDn/5ng+KFjZqtwucP/IqX0m3Hx6woppQ8B/A6XddB1ZnYlcfo43s+mGPe+PRb9R3176WlyQH8ZwK7O2+OrAfwAwL4G6++HfQB2d7Z3A3imycrt8irPPwfwdkrpZ2Pk12YzW9fZvg7AX+KyBvoigO+Pyq8xYtz79kj7D6C+3Rgppcb+AfgugIO4rFH9fZN19/DllwCmAXyFy09YjwHYiMtv2g91/t/QsE9/jss/7fYDeLXz77tj4NcfA/i/jl9vAPiHzud/BOAPAA4D+E8A14zyno64P41F3x7Hft3xS327gX+aKSqEEC1BM0WFEKIlaEAXQoiWoAFdCCFaggZ0IYRoCRrQhRCiJWhAF0KIlqABXQghWoIGdCGEaAn/DxATXHqvzfqjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2)\n",
    "ax0.imshow(Yreal, cmap=plt.cm.gray)\n",
    "ax1.imshow(Lest, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
